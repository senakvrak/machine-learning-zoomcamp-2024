{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76afbff0-ec68-4d9c-89e7-bd54a212d847",
   "metadata": {},
   "source": [
    "# Homework #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2dec0-09e0-4b0b-b46d-cd5e4225d6aa",
   "metadata": {},
   "source": [
    "**Set up the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa94e3e3-d314-483a-9c9a-2765328a42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fafcec-e64e-4a38-b826-2c0035987f3a",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d70040f6-d7a4-4a7c-b845-9f2aa563c321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bank+marketing.zip', <http.client.HTTPMessage at 0x25922b97b90>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\"\n",
    "filename = \"bank+marketing.zip\"\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7fbb7419-b81b-41be-856a-8807791c35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/MONSTER/machine-learning-zoomcamp-2024/bank+marketing/bank/bank-full.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0b443148-06dc-4eee-903d-56045667a8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1229117-a6e2-496e-afa0-9860414dc55c",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "291b6f67-f859-4190-9899-6a6cef5ae41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "balance      0\n",
       "housing      0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the features\n",
    "base = [\"age\",\"job\",\"marital\",\"education\",\"balance\",\"housing\",\"contact\",\"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\",\"y\"]\n",
    "df_new = df[base]\n",
    "\n",
    "# Check if the missing values are presented in the features\n",
    "df_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "10f08cc9-368a-433e-ae8c-8e85b371cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "balance       int64\n",
       "housing      object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1c1fc-5a65-47f2-8961-f602e620d6da",
   "metadata": {},
   "source": [
    "**Question 1** <br>\n",
    "What is the most frequent observation (mode) for the column education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "425a5040-7bc2-4760-8d63-b13daaf39701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent observation for education: secondary\n"
     ]
    }
   ],
   "source": [
    "mode_education = df['education'].mode()[0]\n",
    "print(\"Most frequent observation for education:\", mode_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c405ae1-d128-47f2-a829-3975e1d564b4",
   "metadata": {},
   "source": [
    "**Question 2** <br>\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compete the correlation coeffiecient between every pair of features. <br>\n",
    "What are two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "25ccc7d6-e1e9-4f0e-9723-487157d8b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n",
      "Two features with the highest correlation: ('previous', 'pdays')\n"
     ]
    }
   ],
   "source": [
    "# Selecting only numerical columns\n",
    "numerical_features = df_new.select_dtypes(include=[\"int64\"])\n",
    "\n",
    "# Creating the correlation matrix\n",
    "correlation_matrix = numerical_features.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Find the two features with the highest correlation (ignoring self-correlation)\n",
    "correlation_pairs = correlation_matrix.unstack().sort_values(kind = \"quicksort\", ascending = False)\n",
    "\n",
    "# Filtering out self-correlation (correlation of a feature with itself)\n",
    "high_corr = correlation_pairs[correlation_pairs < 1].idxmax()\n",
    "\n",
    "print(\"Two features with the highest correlation:\", high_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e7f9f-b511-49f9-9ea9-4e850d6de54a",
   "metadata": {},
   "source": [
    "**Target Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ac03c572-aaab-4b30-b9ac-fb896e319ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         no\n",
       "1         no\n",
       "2         no\n",
       "3         no\n",
       "4         no\n",
       "        ... \n",
       "45206    yes\n",
       "45207    yes\n",
       "45208    yes\n",
       "45209     no\n",
       "45210     no\n",
       "Name: y, Length: 45211, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "01ba407e-886d-4b41-841b-b712a0fa2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_20892\\3319070600.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_new.loc[:, \"y\"] = df_new[\"y\"].replace({\"yes\": 1, \"no\": 0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "45206    1\n",
       "45207    1\n",
       "45208    1\n",
       "45209    0\n",
       "45210    0\n",
       "Name: y, Length: 45211, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode y variable\n",
    "# Replace 'yes' with 1 and 'no' with 0 in the target column 'y'\n",
    "df_new.loc[:, \"y\"] = df_new[\"y\"].replace({\"yes\": 1, \"no\": 0})\n",
    "df_new[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4fa9da-d8c9-45c8-846c-ef0141eedb8f",
   "metadata": {},
   "source": [
    "**Split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0d7bacdb-00a8-4833-a5b2-909de5ef0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 27126 samples\n",
      "Validation set: 9042 samples\n",
      "Test set: 9043 samples\n"
     ]
    }
   ],
   "source": [
    "# Separate the features (X) and the target (y)\n",
    "X = df_new.drop(columns=['y'])\n",
    "y = df_new['y']\n",
    "\n",
    "# First split: 60% train, 40% (to be split further into val and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split: 50% of the temp set goes to val and 50% to test (results in 20% each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3608d-c2a3-4ae4-a50d-e8ee9ec2a511",
   "metadata": {},
   "source": [
    "**Question 3** <br>\n",
    "* Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using round(score, 2).\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "* contact\n",
    "* education\n",
    "* housing\n",
    "* poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4da957e5-4a18-4d04-a72c-9789138f1cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poutcome</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MI Score\n",
       "poutcome       0.03\n",
       "month          0.02\n",
       "job            0.01\n",
       "housing        0.01\n",
       "contact        0.01\n",
       "marital        0.00\n",
       "education      0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable with the highest mutual information score is: poutcome (0.03)\n"
     ]
    }
   ],
   "source": [
    "# Define the categorical variables of interest\n",
    "categorical = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a function to calculate mutual information\n",
    "def calculate_mi(series):\n",
    "    return mutual_info_score(series, y_train)  # Use y_train as the target\n",
    "\n",
    "# Apply the function to the specified categorical variables\n",
    "mi_scores = X_train[categorical].apply(calculate_mi)\n",
    "\n",
    "# Convert the series to a DataFrame and round the scores to 2 decimals\n",
    "mi_df = mi_scores.to_frame(name='MI Score').round(2)\n",
    "\n",
    "# Sort the mutual information scores in descending order\n",
    "mi_df = mi_df.sort_values(by='MI Score', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "display(mi_df)\n",
    "\n",
    "# Get the variable with the highest mutual information score\n",
    "highest_mi_variable = mi_df.index[0]  # Get the index of the first row (variable name)\n",
    "highest_mi_score = mi_df['MI Score'].max()  # Get the highest score\n",
    "\n",
    "# Print the final output in the desired format\n",
    "print(f\"The variable with the highest mutual information score is: {highest_mi_variable} ({highest_mi_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa56c4-c621-473f-b6d0-c2787bdea9ce",
   "metadata": {},
   "source": [
    "**Question 4** <br>\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9df3c7e0-c58f-4dbd-9fc3-f386b539a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_20892\\728217474.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_new.drop(columns=['y'])\n",
    "y = df_new['y']  # Target variable\n",
    "\n",
    "# Replace 'yes' and 'no' in target variable with 1 and 0\n",
    "y = y.replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f123265f-ba88-4512-9997-f3da9610a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 58,\n",
       " 'job': 'management',\n",
       " 'marital': 'married',\n",
       " 'education': 'tertiary',\n",
       " 'balance': 2143,\n",
       " 'housing': 'yes',\n",
       " 'contact': 'unknown',\n",
       " 'day': 5,\n",
       " 'month': 'may',\n",
       " 'duration': 261,\n",
       " 'campaign': 1,\n",
       " 'pdays': -1,\n",
       " 'previous': 0,\n",
       " 'poutcome': 'unknown'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "X_train_dict = X.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse = False) # Initialize DictVectorizer\n",
    "X_train_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0023e81d-0f1b-4915-811e-2a0bfbfdb9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.800e+01, 2.143e+03, 1.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [4.400e+01, 2.900e+01, 1.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.300e+01, 2.000e+00, 1.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [7.200e+01, 5.715e+03, 5.000e+00, ..., 1.000e+00, 0.000e+00,\n",
       "        3.000e+00],\n",
       "       [5.700e+01, 6.680e+02, 4.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.700e+01, 2.971e+03, 2.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.100e+01]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the training data using DictVectorizer\n",
    "X_encoded = dv.fit_transform(X_train_dict)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9c09b10d-9f81-4b9b-ae56-141c95605a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation dataset: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and validation sets (60% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model with specified parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation dataset\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy on the validation dataset\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Round the accuracy to 2 decimal digits\n",
    "rounded_accuracy = round(accuracy, 2)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy on the validation dataset: {rounded_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24af8f3-f3f8-43b6-a067-b69111839baa",
   "metadata": {},
   "source": [
    "**Question 5** <br>\n",
    "* Let's find the least useful feature using the feature elimination technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "* age\n",
    "* balance\n",
    "* marital\n",
    "* previous\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "df089edb-052e-4311-8426-3057a7bdb661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_20892\\3553651069.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "## Same as in Q4\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df_new.drop(columns=['y'])\n",
    "y = df_new['y']  # Target variable\n",
    "\n",
    "# Replace 'yes' and 'no' in target variable with 1 and 0\n",
    "y = y.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# One hot encoding\n",
    "X_train_dict = X.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse = False) # Initialize DictVectorizer\n",
    "\n",
    "# Fit and transform the training data using DictVectorizer\n",
    "X_encoded = dv.fit_transform(X_train_dict)\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model with all features\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3234fa54-0a6c-4911-a20f-f99d6057f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: 0.8992590954329316\n",
      "Feature: balance, Accuracy Difference: -0.0001\n",
      "Feature: age, Accuracy Difference: 0.0000\n",
      "Feature: previous, Accuracy Difference: 0.0003\n",
      "\n",
      "The feature with the smallest accuracy difference: balance\n"
     ]
    }
   ],
   "source": [
    "# Calculate the original accuracy\n",
    "original_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Original accuracy: {original_accuracy}\")\n",
    "\n",
    "# List of specific features to check\n",
    "features_to_check = ['age', 'balance', 'marital', 'previous']\n",
    "\n",
    "# List to store accuracy differences\n",
    "accuracy_differences = []\n",
    "\n",
    "# Iterate over each feature in the specific list\n",
    "for feature in features_to_check:\n",
    "    \n",
    "    if feature in dv.feature_names_:\n",
    "        # Drop the specific feature\n",
    "        X_train_dropped = np.delete(X_train, dv.feature_names_.index(feature), axis=1)\n",
    "        X_val_dropped = np.delete(X_val, dv.feature_names_.index(feature), axis=1)\n",
    "    \n",
    "        # Train model without the feature\n",
    "        model.fit(X_train_dropped, y_train)\n",
    "    \n",
    "        # Predict and calculate accuracy without the feature\n",
    "        y_val_pred_dropped = model.predict(X_val_dropped)\n",
    "        accuracy_dropped = accuracy_score(y_val, y_val_pred_dropped)\n",
    "    \n",
    "        # Calculate the difference in accuracy\n",
    "        accuracy_diff = original_accuracy - accuracy_dropped\n",
    "        accuracy_differences.append((feature, accuracy_diff))\n",
    "\n",
    "# Sort the features by accuracy difference in ascending order\n",
    "accuracy_differences.sort(key=lambda x: x[1])\n",
    "\n",
    "# Display all specified features and their accuracy differences\n",
    "for feature, diff in accuracy_differences:\n",
    "    print(f\"Feature: {feature}, Accuracy Difference: {diff:.4f}\")\n",
    "\n",
    "# Display the feature with the smallest accuracy difference\n",
    "print(f\"\\nThe feature with the smallest accuracy difference: {accuracy_differences[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cd4a4-efc5-4cfa-ad1a-bcaee4e7a2d6",
   "metadata": {},
   "source": [
    "**Question 6** <br>\n",
    "* Now let's train a regularized logistic regression.\n",
    "* Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "* Train models using all the features as in Q4.\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these C leads to the best accuracy on the validation set?\n",
    "* 0.01\n",
    "* 0.1\n",
    "* 1\n",
    "* 10\n",
    "* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5ba07cb6-dd87-4cdc-bbf8-3173ad07385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_20892\\3553651069.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "## Same as in Q4\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df_new.drop(columns=['y'])\n",
    "y = df_new['y']  # Target variable\n",
    "\n",
    "# Replace 'yes' and 'no' in target variable with 1 and 0\n",
    "y = y.replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# One hot encoding\n",
    "X_train_dict = X.to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse = False) # Initialize DictVectorizer\n",
    "\n",
    "# Fit and transform the training data using DictVectorizer\n",
    "X_encoded = dv.fit_transform(X_train_dict)\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model with all features\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8b672baf-85fb-4d6a-9aaf-f7aa1e1ac1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: Validation Accuracy = 0.898\n",
      "C = 0.1: Validation Accuracy = 0.899\n",
      "C = 1: Validation Accuracy = 0.899\n",
      "C = 10: Validation Accuracy = 0.899\n",
      "C = 100: Validation Accuracy = 0.899\n",
      "\n",
      "The best C value is 0.1, with an accuracy of 0.899\n"
     ]
    }
   ],
   "source": [
    "# List of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Dictionary to store the accuracy for each value of C\n",
    "accuracy_dict = {}\n",
    "\n",
    "# Train a model for each value of C and calculate accuracy\n",
    "for C in C_values:\n",
    "    # Create the logistic regression model with the current C\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracy_dict[C] = round(accuracy, 3)\n",
    "    \n",
    "    print(f\"C = {C}: Validation Accuracy = {accuracy:.3f}\")\n",
    "\n",
    "# Find the C value with the highest accuracy\n",
    "best_C = max(accuracy_dict, key=accuracy_dict.get)\n",
    "best_accuracy = accuracy_dict[best_C]\n",
    "\n",
    "# Display the best C value and its accuracy\n",
    "print(f\"\\nThe best C value is {best_C}, with an accuracy of {best_accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
